{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import module\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Backend\n",
    "from tensorflow.keras import backend as K\n",
    "# Utils\n",
    "from tensorflow.keras.utils import convert_all_kernels_in_model\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# out\n",
    "model = create_model(include_top=True)\n",
    "classes = eval(open('D:/DeepLearning/model/inception-v4/keras-inceptionV4/validation_utils/class_names.txt', 'r').read())\n",
    "img_path = 'D:/DeepLearning/model/inception-v4/keras-inceptionV4/elephant.jpg'\n",
    "img = get_processed_image(img_path)\n",
    "preds = model.predict(img)\n",
    "print(\"Class is: \" + classes[np.argmax(preds)-1])\n",
    "print(\"Certainty is: \" + str(preds[0][np.argmax(preds)]))\n",
    "\n",
    "img_path = 'D:/DeepLearning/model/inception-v4/keras-inceptionV4/elephant.jpg'\n",
    "img = get_processed_image(img_path)\n",
    "preds = model.predict(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# preprocess the input\n",
    "def preprocess_input(x):\n",
    "    x = np.divide(x, 255.0)\n",
    "    x = np.subtract(x, 0.5)\n",
    "    x = np.multiply(x, 2.0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convolution and BatchNormalization\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "              padding='same', strides=(1, 1), use_bias=False):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN. \n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first': # the position of channel dimension\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    x = Convolution2D(nb_filter, (num_row, num_col),\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias,\n",
    "                      kernel_regularizer=regularizers.l2(0.00004),\n",
    "                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal', seed=None))(x)\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Inception-A block\n",
    "def block_inception_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        \n",
    "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
    "    \n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
    "    \n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    \n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
    "    \n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# reduction-A block\n",
    "def block_reduction_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        \n",
    "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "    \n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
    "    \n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
    "    \n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Inception-B block\n",
    "def block_inception_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        \n",
    "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
    "    \n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 7, 1) # !!!\n",
    "    \n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
    "    \n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
    "    \n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# reduction-B block\n",
    "def block_reduction_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Inception-C block\n",
    "def block_inception_c(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
    "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
    "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# inception-v4 basement\n",
    "def inception_v4_base(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
    "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "        net = block_inception_a(net)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "        net = block_inception_b(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    # 3 x Inception-C blocks\n",
    "    for idx in range(3):\n",
    "        net = block_inception_c(net)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# inception-v4\n",
    "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
    "    '''\n",
    "    Creates the inception v4 network\n",
    "    Args:\n",
    "        num_classes: number of classes\n",
    "        dropout_keep_prob: float, the fraction to keep before final layer.\n",
    "    \n",
    "    Returns: \n",
    "        logits: the logits outputs of the model.\n",
    "    '''\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputs = Input((3, 299, 299))\n",
    "    else:\n",
    "        inputs = Input((299, 299, 3))\n",
    "\n",
    "    # Make inception base\n",
    "    x = inception_v4_base(inputs)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "    if include_top:\n",
    "        # 1 x 1 x 1536\n",
    "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
    "        x = Dropout(dropout_keep_prob)(x)\n",
    "        x = Flatten()(x)\n",
    "        # 1536\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='inception_v4')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "        if include_top:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
    "        else:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9296b46b5971573064d12e4669110969')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create the inception-v4\n",
    "def create_model(num_classes=1001, dropout_prob=0.8, weights=None, include_top=True):\n",
    "    return inception_v4(num_classes, dropout_prob, weights, include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Crop the central region of the image.\n",
    "def central_crop(image, central_fraction):\n",
    "    if central_fraction <= 0.0 or central_fraction > 1.0:\n",
    "         raise ValueError('central_fraction must be within (0, 1]')\n",
    "    if central_fraction == 1.0:\n",
    "         return image\n",
    "        \n",
    "    img_shape = image.shape\n",
    "    depth = img_shape[2]\n",
    "    fraction_offset = int(1 / ((1 - central_fraction) / 2.0))\n",
    "    bbox_h_start = int(np.divide(img_shape[0], fraction_offset))\n",
    "    bbox_w_start = int(np.divide(img_shape[1], fraction_offset))\n",
    "    \n",
    "    bbox_h_size = int(img_shape[0] - bbox_h_start * 2)\n",
    "    bbox_w_size = int(img_shape[1] - bbox_w_start * 2)\n",
    "    \n",
    "    image = image[bbox_h_start:bbox_h_start+bbox_h_size, bbox_w_start:bbox_w_start+bbox_w_size]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# processed the image\n",
    "def get_processed_image(img_path):\n",
    "    # Load image and convert from BGR to RGB\n",
    "    im = np.asarray(cv2.imread(img_path))[:,:,::-1]\n",
    "    # crop the image\n",
    "    im = central_crop(im, 0.875)\n",
    "    im = cv2.resize(im, (299, 299))\n",
    "    im = preprocess_input(im)\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        im = np.transpose(im, (2,0,1))\n",
    "        im = im.reshape(-1,3,299,299)\n",
    "    else:\n",
    "        im = im.reshape(-1,299,299,3)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e8d930e888401f92534377ea04a9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b40177ee49e4f8682efb7e40fe4b4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'central_crop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3c8d7c75ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mflower_jpg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mflower_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflower_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_processed_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflower_jpg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mlabel_flower_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f5dfccf3eeee>\u001b[0m in \u001b[0;36mget_processed_image\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# crop the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcentral_crop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.875\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'central_crop' is not defined"
     ]
    }
   ],
   "source": [
    "# load the flower\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "i = 0\n",
    "file_path = 'flower_photos/'\n",
    "flower_img = np.zeros((0, 299, 299, 3))\n",
    "label_flower_img = []\n",
    "for class_ in tqdm_notebook(classes):\n",
    "    file_dir = os.path.join(file_path, class_)\n",
    "    for file in tqdm_notebook(os.listdir(file_dir)):\n",
    "        flower_jpg = file_dir + '/' + file\n",
    "        flower_img = np.append(flower_img, get_processed_image(flower_jpg), axis=0)\n",
    "        label_flower_img.append(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((633, 299, 299, 3), 633)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_img.shape, len(label_flower_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(flower_img, label_flower_img, train_size = 0.85)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(num_classes=5, dropout_prob=0.8, include_top=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer = 'sgd',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2 (BatchNo (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization_v2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_1 (Batch (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_v2_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_2 (Batch (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_v2_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 96)   55296       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_3 (Batch (None, 73, 73, 96)   288         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 96)   0           batch_normalization_v2_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 73, 73, 160)  0           max_pooling2d[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 73, 73, 64)   10240       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_6 (Batch (None, 73, 73, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 73, 73, 64)   0           batch_normalization_v2_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 73, 73, 64)   28672       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_7 (Batch (None, 73, 73, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 73, 73, 64)   0           batch_normalization_v2_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 64)   10240       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 73, 73, 64)   28672       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_4 (Batch (None, 73, 73, 64)   192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_8 (Batch (None, 73, 73, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 64)   0           batch_normalization_v2_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 73, 73, 64)   0           batch_normalization_v2_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 96)   55296       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 71, 71, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_5 (Batch (None, 71, 71, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_9 (Batch (None, 71, 71, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 96)   0           batch_normalization_v2_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 71, 71, 96)   0           batch_normalization_v2_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 71, 71, 192)  0           activation_5[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 192)  331776      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_10 (Batc (None, 35, 35, 192)  576         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 192)  0           batch_normalization_v2_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 35, 35, 384)  0           activation_10[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_14 (Batc (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 96)   55296       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_12 (Batc (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_15 (Batc (None, 35, 35, 96)   288         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 384)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 96)   55296       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   82944       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_11 (Batc (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_13 (Batc (None, 35, 35, 96)   288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_16 (Batc (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_17 (Batc (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 384)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_21 (Batc (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 96)   55296       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_19 (Batc (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_22 (Batc (None, 35, 35, 96)   288         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 384)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 96)   55296       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   82944       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_18 (Batc (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_20 (Batc (None, 35, 35, 96)   288         conv2d_20[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_23 (Batc (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_24 (Batc (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 384)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_28 (Batc (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_26 (Batc (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_29 (Batc (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 384)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 96)   55296       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_25 (Batc (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_27 (Batc (None, 35, 35, 96)   288         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_30 (Batc (None, 35, 35, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_31 (Batc (None, 35, 35, 96)   288         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35, 35, 384)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_35 (Batc (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 96)   55296       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_33 (Batc (None, 35, 35, 64)   192         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_36 (Batc (None, 35, 35, 96)   288         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v2_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 384)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 96)   55296       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 96)   82944       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_32 (Batc (None, 35, 35, 96)   288         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_34 (Batc (None, 35, 35, 96)   288         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_37 (Batc (None, 35, 35, 96)   288         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_38 (Batc (None, 35, 35, 96)   288         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v2_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 35, 35, 384)  0           activation_32[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 192)  73728       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_40 (Batc (None, 35, 35, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 192)  0           batch_normalization_v2_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 224)  387072      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_41 (Batc (None, 35, 35, 224)  672         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 224)  0           batch_normalization_v2_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 384)  1327104     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 256)  516096      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_39 (Batc (None, 17, 17, 384)  1152        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_42 (Batc (None, 17, 17, 256)  768         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 384)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 17, 17, 1024) 0           activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_47 (Batc (None, 17, 17, 192)  576         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  258048      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_48 (Batc (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 224)  301056      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_44 (Batc (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_v2_49 (Batc (None, 17, 17, 224)  672         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 224)  301056      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 224)  351232      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_45 (Batc (None, 17, 17, 224)  672         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_50 (Batc (None, 17, 17, 224)  672         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 1024) 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 256)  401408      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 256)  401408      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_43 (Batc (None, 17, 17, 384)  1152        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_46 (Batc (None, 17, 17, 256)  768         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_51 (Batc (None, 17, 17, 256)  768         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_52 (Batc (None, 17, 17, 128)  384         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v2_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 17, 17, 1024) 0           activation_43[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_57 (Batc (None, 17, 17, 192)  576         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  258048      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_58 (Batc (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 224)  301056      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_54 (Batc (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_59 (Batc (None, 17, 17, 224)  672         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 224)  301056      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 224)  351232      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_55 (Batc (None, 17, 17, 224)  672         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_60 (Batc (None, 17, 17, 224)  672         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 1024) 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 256)  401408      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 256)  401408      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_53 (Batc (None, 17, 17, 384)  1152        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_56 (Batc (None, 17, 17, 256)  768         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_61 (Batc (None, 17, 17, 256)  768         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_62 (Batc (None, 17, 17, 128)  384         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_56[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v2_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 17, 17, 1024) 0           activation_53[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_67 (Batc (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_68 (Batc (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 224)  301056      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_64 (Batc (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_69 (Batc (None, 17, 17, 224)  672         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 224)  301056      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 224)  351232      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_65 (Batc (None, 17, 17, 224)  672         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_70 (Batc (None, 17, 17, 224)  672         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 1024) 0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 256)  401408      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 256)  401408      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_63 (Batc (None, 17, 17, 384)  1152        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_v2_66 (Batc (None, 17, 17, 256)  768         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_71 (Batc (None, 17, 17, 256)  768         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_72 (Batc (None, 17, 17, 128)  384         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v2_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 17, 17, 1024) 0           activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_77 (Batc (None, 17, 17, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_77[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 192)  258048      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_78 (Batc (None, 17, 17, 192)  576         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_78[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 224)  301056      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_74 (Batc (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_79 (Batc (None, 17, 17, 224)  672         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_79[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 224)  301056      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 224)  351232      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_75 (Batc (None, 17, 17, 224)  672         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_80 (Batc (None, 17, 17, 224)  672         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_80[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 1024) 0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 256)  401408      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 256)  401408      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_73 (Batc (None, 17, 17, 384)  1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_76 (Batc (None, 17, 17, 256)  768         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_81 (Batc (None, 17, 17, 256)  768         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_82 (Batc (None, 17, 17, 128)  384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_76[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_81[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v2_82[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 17, 17, 1024) 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_87 (Batc (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_87[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  258048      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_88 (Batc (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_88[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 224)  301056      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_84 (Batc (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_89 (Batc (None, 17, 17, 224)  672         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_84[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_89[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 224)  301056      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 224)  351232      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_85 (Batc (None, 17, 17, 224)  672         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_90 (Batc (None, 17, 17, 224)  672         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_85[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_90[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 17, 17, 1024) 0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 256)  401408      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 256)  401408      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_83 (Batc (None, 17, 17, 384)  1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_86 (Batc (None, 17, 17, 256)  768         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_91 (Batc (None, 17, 17, 256)  768         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_92 (Batc (None, 17, 17, 128)  384         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_83[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_86[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_91[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v2_92[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 17, 17, 1024) 0           activation_83[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_97 (Batc (None, 17, 17, 192)  576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 192)  258048      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_98 (Batc (None, 17, 17, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_98[0][0]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 224)  301056      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_94 (Batc (None, 17, 17, 192)  576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_99 (Batc (None, 17, 17, 224)  672         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v2_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 224)  301056      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 224)  351232      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_95 (Batc (None, 17, 17, 224)  672         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_100 (Bat (None, 17, 17, 224)  672         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 224)  0           batch_normalization_v2_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 224)  0           batch_normalization_v2_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 17, 17, 1024) 0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 256)  401408      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 256)  401408      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_93 (Batc (None, 17, 17, 384)  1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_96 (Batc (None, 17, 17, 256)  768         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_101 (Bat (None, 17, 17, 256)  768         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_102 (Bat (None, 17, 17, 128)  384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v2_93[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 256)  0           batch_normalization_v2_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v2_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v2_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17, 17, 1024) 0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_107 (Bat (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v2_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  258048      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_108 (Bat (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v2_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 224)  301056      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_104 (Bat (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_109 (Bat (None, 17, 17, 224)  672         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v2_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 224)  0           batch_normalization_v2_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 224)  301056      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 224)  351232      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_105 (Bat (None, 17, 17, 224)  672         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_110 (Bat (None, 17, 17, 224)  672         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 224)  0           batch_normalization_v2_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 224)  0           batch_normalization_v2_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 17, 17, 1024) 0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 256)  401408      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 256)  401408      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_103 (Bat (None, 17, 17, 384)  1152        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_106 (Bat (None, 17, 17, 256)  768         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_111 (Bat (None, 17, 17, 256)  768         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_112 (Bat (None, 17, 17, 128)  384         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 384)  0           batch_normalization_v2_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v2_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v2_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 128)  0           batch_normalization_v2_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 17, 17, 1024) 0           activation_103[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 256)  262144      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_115 (Bat (None, 17, 17, 256)  768         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v2_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 256)  458752      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_116 (Bat (None, 17, 17, 256)  768         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 256)  0           batch_normalization_v2_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 320)  573440      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_113 (Bat (None, 17, 17, 192)  576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_117 (Bat (None, 17, 17, 320)  960         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 192)  0           batch_normalization_v2_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 320)  0           batch_normalization_v2_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 192)    331776      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 320)    921600      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_114 (Bat (None, 8, 8, 192)    576         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_118 (Bat (None, 8, 8, 320)    960         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 192)    0           batch_normalization_v2_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 320)    0           batch_normalization_v2_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1024)   0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 8, 8, 1536)   0           activation_114[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_123 (Bat (None, 8, 8, 384)    1152        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v2_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 448)    516096      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_124 (Bat (None, 8, 8, 448)    1344        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, 8, 448)    0           batch_normalization_v2_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 512)    688128      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_120 (Bat (None, 8, 8, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_125 (Bat (None, 8, 8, 512)    1536        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v2_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, 8, 512)    0           batch_normalization_v2_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 256)    294912      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 256)    294912      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 256)    393216      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 256)    393216      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 8, 8, 1536)   0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 256)    393216      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_121 (Bat (None, 8, 8, 256)    768         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_122 (Bat (None, 8, 8, 256)    768         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_126 (Bat (None, 8, 8, 256)    768         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_127 (Bat (None, 8, 8, 256)    768         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 256)    393216      average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_119 (Bat (None, 8, 8, 256)    768         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_128 (Bat (None, 8, 8, 256)    768         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 512)    0           activation_121[0][0]             \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 8, 8, 512)    0           activation_126[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 8, 8, 1536)   0           activation_119[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_133 (Bat (None, 8, 8, 384)    1152        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v2_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 448)    516096      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_134 (Bat (None, 8, 8, 448)    1344        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 448)    0           batch_normalization_v2_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 512)    688128      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_130 (Bat (None, 8, 8, 384)    1152        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_135 (Bat (None, 8, 8, 512)    1536        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v2_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 8, 8, 512)    0           batch_normalization_v2_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 256)    294912      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 256)    294912      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 256)    393216      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 256)    393216      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 8, 8, 1536)   0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 256)    393216      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_131 (Bat (None, 8, 8, 256)    768         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_132 (Bat (None, 8, 8, 256)    768         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_136 (Bat (None, 8, 8, 256)    768         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_137 (Bat (None, 8, 8, 256)    768         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 256)    393216      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_129 (Bat (None, 8, 8, 256)    768         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_138 (Bat (None, 8, 8, 256)    768         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 8, 8, 512)    0           activation_131[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 512)    0           activation_136[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 1536)   0           activation_129[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_143 (Bat (None, 8, 8, 384)    1152        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v2_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 8, 8, 448)    516096      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_144 (Bat (None, 8, 8, 448)    1344        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 8, 8, 448)    0           batch_normalization_v2_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 8, 8, 384)    589824      concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 8, 8, 512)    688128      activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_140 (Bat (None, 8, 8, 384)    1152        conv2d_140[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_145 (Bat (None, 8, 8, 512)    1536        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 8, 8, 384)    0           batch_normalization_v2_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 8, 8, 512)    0           batch_normalization_v2_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 8, 8, 256)    294912      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 8, 8, 256)    294912      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 8, 8, 256)    393216      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 8, 8, 256)    393216      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 8, 8, 1536)   0           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 8, 8, 256)    393216      concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_141 (Bat (None, 8, 8, 256)    768         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_142 (Bat (None, 8, 8, 256)    768         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_146 (Bat (None, 8, 8, 256)    768         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_147 (Bat (None, 8, 8, 256)    768         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, 8, 256)    393216      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_139 (Bat (None, 8, 8, 256)    768         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_148 (Bat (None, 8, 8, 256)    768         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 8, 8, 512)    0           activation_141[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 8, 8, 512)    0           activation_146[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 8, 8, 256)    0           batch_normalization_v2_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 1536)   0           activation_139[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 1, 1, 1536)   0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 1, 1536)   0           average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1536)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            7685        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,182,085\n",
      "Trainable params: 41,118,917\n",
      "Non-trainable params: 63,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples, validate on 1 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 106s 106s/sample - loss: 4.1059 - accuracy: 0.0000e+00 - val_loss: 100.8473 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 5.6475 - accuracy: 0.0000e+00 - val_loss: 760.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 3.2881 - accuracy: 1.0000 - val_loss: 1027.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 4.6832 - accuracy: 0.0000e+00 - val_loss: 1231.2881 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 4.0230 - accuracy: 0.0000e+00 - val_loss: 996.5499 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 4.4755 - accuracy: 0.0000e+00 - val_loss: 2.5374 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 3.0007 - accuracy: 1.0000 - val_loss: 2.5374 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 1s/sample - loss: 2.7383 - accuracy: 1.0000 - val_loss: 2.5374 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/sample - loss: 2.7768 - accuracy: 1.0000 - val_loss: 2.5374 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 3.0216 - accuracy: 1.0000 - val_loss: 2.5374 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "callbacks = [\n",
    "    #keras.callbacks.TensorBoard(logdir),\n",
    "    #keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "    #                                save_best_only = True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta= 1e-3 )\n",
    "]\n",
    "\n",
    "history = model.fit(img, [0], epochs=10,\n",
    "                    validation_data=(img,[0]),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 1 input samples and 2752 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-874a546de6cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m history = model.fit(img, y_train, epochs=10,\n\u001b[0;32m     10\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     callbacks = callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2651\u001b[0m       \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2652\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2653\u001b[1;33m         \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_array_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2654\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2655\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    444\u001b[0m                      \u001b[1;34m'the same number of samples as target arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                      \u001b[1;34m'Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input samples '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                      'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[0;32m    447\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[1;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 1 input samples and 2752 target samples."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "callbacks = [\n",
    "    #keras.callbacks.TensorBoard(logdir),\n",
    "    #keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "    #                                save_best_only = True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta= 1e-3 )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10,\n",
    "                    validation_data=(x_valid,y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08606667, 0.11585543, 0.32853067, 0.32825434, 0.1412929 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(np.array([x_train[0]]))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([x_train[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
